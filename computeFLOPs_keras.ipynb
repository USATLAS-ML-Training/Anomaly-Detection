{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the number of floating point operations of a model\n",
    "\n",
    "For models running in the hardware triggering system of a particle detector, the model latency and resource consumption is equally as important as the model accuracy. A reasonable trade-off between the two must therefore be made, often accomplished by iteratively compressing and synthesizing the model to get an accurate resource/latency estimate.\n",
    "\n",
    "Since evaluating the DNN firmware of your algorithm is slightly out of the scope for this challenge (although we do encourage you to give it a try! If you have a Vivado license, have a look at the [hls4ml tutorials](https://github.com/fastmachinelearning/hls4ml-tutorial) and see what you get!), we will instead count the number of floating point operations (FLOPs)in the model, giving us a reasonable idea of the model size and hence resource consumption.\n",
    "\n",
    "Three examples are provided: Using the Tensorflow graph, using the keras-flops tool and one back of the envelope calculation. The examples below are for Tensorflow Keras models and must be adapted if using other libraries.\n",
    "\n",
    "This code is based on TensorFlow 2.3.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch the autoencoder\n",
    "\n",
    "We'll use the fully connected dense neural network autoencoder for this demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, Activation, Layer, ReLU, LeakyReLU\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# build model\n",
    "input_shape = 57\n",
    "latent_dimension = 3\n",
    "num_nodes=[16,8]\n",
    "\n",
    "#encoder\n",
    "inputArray = Input(shape=(input_shape))\n",
    "x = Dense(num_nodes[0], use_bias=False)(inputArray)\n",
    "x = Activation('relu')(x)\n",
    "x = Dense(latent_dimension, use_bias=False)(x)\n",
    "encoder = Activation('relu')(x)\n",
    "\n",
    "#decoder\n",
    "x = Dense(num_nodes[1], use_bias=False)(encoder)\n",
    "x = Activation('relu')(x)\n",
    "x = Dense(num_nodes[0], use_bias=False)(x)\n",
    "x = Activation('relu')(x)\n",
    "decoder = Dense(input_shape)(x)\n",
    "\n",
    "#create autoencoder\n",
    "autoencoder = Model(inputs = inputArray, outputs=decoder)\n",
    "autoencoder.summary()\n",
    "autoencoder.compile(optimizer = tf.keras.optimizers.Adam(), loss='mse')\n",
    "\n",
    "autoencoder.save('ae.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Example 1: Using the TF graph\n",
    "Use the TF graph to profile the model and get the total number of floating point ops:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flops():\n",
    "    session = tf.compat.v1.Session()\n",
    "    graph = tf.compat.v1.get_default_graph()\n",
    "\n",
    "    with graph.as_default():\n",
    "        with session.as_default():\n",
    "            model = tf.keras.models.load_model('ae.h5')\n",
    "            \n",
    "            run_meta = tf.compat.v1.RunMetadata()\n",
    "            opts = tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()\n",
    "\n",
    "            # Optional: save printed results to file\n",
    "            # flops_log_path = os.path.join(tempfile.gettempdir(), 'tf_flops_log.txt')\n",
    "            # opts['output'] = 'file:outfile={}'.format(flops_log_path)\n",
    "\n",
    "            # We use the Keras session graph in the call to the profiler.\n",
    "            flops = tf.compat.v1.profiler.profile(graph=graph,\n",
    "                                                  run_meta=run_meta, cmd='op', options=opts)\n",
    "\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "\n",
    "    return flops.total_float_ops\n",
    "\n",
    "\n",
    "print('TF Profile: Total number of FLOPs =  {}'.format(get_flops()))\n",
    "# Profile:\n",
    "# node name | # float_ops\n",
    "# Mul                      2.02k float_ops (100.00%, 49.95%)\n",
    "# Add                      2.02k float_ops (50.05%, 49.93%)\n",
    "# Sub                          5 float_ops (0.12%, 0.12%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this model has 4,054 floating point operations. Check your terminal for some more detailed per-layer information. If your model is a Keras/TensorFlow model we recommend using this way of estimating the FLOPs.\n",
    "\n",
    "However, if you are for some reason forced to compute it by hand, you can find an example below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Doing a back of the envelope calculation\n",
    "\n",
    "Below you can find an example of how to compute the FLOPs of a linear/conv2D layer (based on [keras-Opcounter](https://github.com/kentaroy47/keras-Opcounter)), not taking the activations into account. One multiply-and-accumulate (MAC) operation is counted as 2 FLOPs, and one ADD is counted as one FLOP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_linear(layers):\n",
    "    MAC = layers.output_shape[1] * layers.input_shape[1]\n",
    "    if layers.get_config()[\"use_bias\"]:\n",
    "        ADD = layers.output_shape[1]\n",
    "    else:\n",
    "        ADD = 0\n",
    "    return MAC*2 + ADD\n",
    "\n",
    "def count_conv2d(layers, log = False):\n",
    "    if log:\n",
    "        print(layers.get_config())\n",
    "\n",
    "    numshifts = int(layers.output_shape[1] * layers.output_shape[2])\n",
    "    \n",
    "    MACperConv = layers.get_config()[\"kernel_size\"][0] * layers.get_config()[\"kernel_size\"][1] * layers.input_shape[3] * layers.output_shape[3]\n",
    "    \n",
    "    if layers.get_config()[\"use_bias\"]:\n",
    "        ADD = layers.output_shape[3]\n",
    "    else:\n",
    "        ADD = 0\n",
    "        \n",
    "    return MACperConv * numshifts * 2 + ADD\n",
    "\n",
    "def profile(model, log = False):\n",
    "\n",
    "    layer_name = []\n",
    "    layer_flops = []\n",
    "    inshape = []\n",
    "    weights = []\n",
    "\n",
    "    for layer in model.layers:\n",
    "        if \"act\" in layer.get_config()[\"name\"]:\n",
    "          print (\"Skipping ativation functions\")\n",
    "           \n",
    "        elif \"dense\" in layer.get_config()[\"name\"] or \"fc\" in layer.get_config()[\"name\"]:\n",
    "            layer_flops.append(count_linear(layer))\n",
    "            layer_name.append(layer.get_config()[\"name\"])\n",
    "            inshape.append(layer.input_shape)\n",
    "            weights.append(int(np.sum([K.count_params(p) for p in (layer.trainable_weights)])))\n",
    "            \n",
    "        elif \"conv\" in layer.get_config()[\"name\"] and \"pad\" not in layer.get_config()[\"name\"] and \"bn\" not in layer.get_config()[\"name\"] and \"relu\" not in layer.get_config()[\"name\"] and \"concat\" not in layer.get_config()[\"name\"]:\n",
    "            layer_flops.append(count_conv2d(layer,log))\n",
    "            layer_name.append(layer.get_config()[\"name\"])\n",
    "            inshape.append(layer.input_shape)\n",
    "            weights.append(int(np.sum([K.count_params(p) for p in (layer.trainable_weights)])))\n",
    "            \n",
    "        elif \"res\" in layer.get_config()[\"name\"] and \"branch\" in layer.get_config()[\"name\"]:\n",
    "            layer_flops.append(count_conv2d(layer,log))\n",
    "            layer_name.append(layer.get_config()[\"name\"])\n",
    "            inshape.append(layer.input_shape)\n",
    "            weights.append(int(np.sum([K.count_params(p) for p in (layer.trainable_weights)])))\n",
    "            \n",
    "    return layer_name, layer_flops, inshape, weights\n",
    "\n",
    "def doOPS(model):\n",
    "  print(\"Counting number of FLOPs in model\")\n",
    "\n",
    "  layer_name, layer_flops, inshape, weights = profile(autoencoder)\n",
    "  for name, flop, shape, weight in zip(layer_name, layer_flops, inshape, weights):\n",
    "      print(\"layer:\", name, shape, \" FLOPs:\", flop, \"Weights:\", weight)\n",
    "  totalFlops = sum(layer_flops)\n",
    "  print(\"By hand: Total number of FLOPs = {}\".format(totalFlops) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalGFlops = doOPS(autoencoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this back-of-the envelope calculation, there is some difference between this estimate and the one above albeit relatively small. We will therefor prioritize the number returned by tf profile when evaluating contributions, but whenever this is not possible we'll do a double check.\n",
    "\n",
    "## Example 3: Using the keras-flops tool\n",
    "\n",
    "Another minimal-code example one can use, and which is also built on top of tf.profile, is the library [keras-flops](https://pypi.org/project/keras-flops/). This library supports dense, convolutional and pooling layers. Let's give it a try too:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install keras-flops?\n",
    "#!pip install keras-flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_flops import get_flops\n",
    "\n",
    "# Let's load the model again so we have a clean graph\n",
    "model = tf.keras.models.load_model('ae.h5')\n",
    "    \n",
    "# Compute FLOPs\n",
    "flops = get_flops(autoencoder, batch_size=1)\n",
    "print(\"keras-flops: Total number of FLOPs = {} \".format(flops))\n",
    "# FLOPS: 4.1e-06 G\n",
    "# _TFProfRoot (--/4.11k flops)\n",
    "#   functional_1/dense/MatMul (1.82k/1.82k flops)\n",
    "#   functional_1/dense_4/MatMul (1.82k/1.82k flops)\n",
    "#   functional_1/dense_3/MatMul (256/256 flops)\n",
    "#   functional_1/dense_1/MatMul (96/96 flops)\n",
    "#   functional_1/dense_4/BiasAdd (57/57 flops)\n",
    "#   functional_1/dense_2/MatMul (48/48 flops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
